

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Kafka配置与使用 &mdash; SAwiki v1.0 文档</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/translations.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> SAwiki
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">LogCollection:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Elasticsearch%20snapshot%28HDFS%29.html">Elasticsearch索引备份到HDFS</a></li>
</ul>
<p class="caption"><span class="caption-text">Helm:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Helm/Helm.html">Helm基础与使用</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SAwiki</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Kafka配置与使用</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/LogCollection/Kafka.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="kafka">
<h1>Kafka配置与使用<a class="headerlink" href="#kafka" title="永久链接至标题">¶</a></h1>
<div class="section" id="id1">
<h2>一、简要说明<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h2>
<p>Apache kafka是消息中间件的一种。以下是Kafka中常见的名词：</p>
<p>● producer ：生产者，产生消息。</p>
<p>● consumer：消费者，消费消息。</p>
<p>● topic：每一类的消息称之为一个主题(Topic)</p>
<p>● broker：存放消息的节点</p>
<p>Kafka在大数据方面有广泛的应用。使用Kafka构建实时的数据流通道，利用Kafka本身的高吞吐量的特点，实现上下游的数据转换。</p>
</div>
<div class="section" id="id2">
<h2>二、配置可用单节点Kafka实例<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<p>这里以 <a class="reference external" href="https://archive.apache.org/dist/kafka/2.0.0/kafka_2.11-2.0.0.tgz">kafka_2.11-2.0.0</a> 为例，说明在不同的环境下Kafka的配置与使用。</p>
<div class="section" id="id3">
<h3>2.1 下载包<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h3>
<p>在官网下载相应版本的二进制包，同时也要下载Zookeeper。zookeeper主要保存了kafka的topic、consumer等信息，旧版本的kafka消费者是通过连接zookeeper进行消费的。这里下载的是zookeeper-3.4.9。</p>
</div>
<div class="section" id="zookeeper">
<h3>2.2 Zookeeper配置与使用<a class="headerlink" href="#zookeeper" title="永久链接至标题">¶</a></h3>
<p>二进制Zookeeper包解压之后，bin目录存放的是一些使用脚本，conf目录存放了主要的配置文件。默认config/zoo_sample.cfg文件名修改为zoo.cfg。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">dataDir</span><span class="o">=</span>/soft/zookeeper-3.4.9/data <span class="c1"># zookeeper数据文件存放路径</span>
<span class="nv">clientPort</span><span class="o">=</span><span class="m">2181</span> <span class="c1"># zookeeper启动端口</span>
</pre></div>
</div>
<p>bin目录下常用的是zkServer.sh和zkCli.sh脚本。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./zkServer.sh start <span class="c1"># 启动Zookeeper服务端</span>
./zkCli.sh -server ip:port <span class="c1"># 启动zookeeper客户端，用于查看zookeeper信息</span>
</pre></div>
</div>
<p>Zookeeper是常用的配置存放工具。分布式系统中会使用Zookeeper保存配置信息，Java应用程序连接Zookeeper实现程序配置的热加载。类似的工具还有ETCD，详细的介绍可官网。这里连接zookeeper可以查看到当前Kafka实例中Topic的信息：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>zk: localhost:2181<span class="o">(</span>CONNECTED<span class="o">)</span> <span class="m">2</span><span class="o">]</span> ls /config/topics
<span class="o">[</span>hq-useraccess, datacollectlog, hq-vss, __consumer_offsets<span class="o">]</span>
</pre></div>
</div>
</div>
<div class="section" id="id4">
<h3>2.3 Kafka的配置与使用<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h3>
<p>和Zookeeper类似，二进制包中bin目录存放的是一些使用脚本，conf目录存放了主要的配置文件。Kafka服务端的配置文件是conf/server.properties。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>broker.id<span class="o">=</span><span class="m">0</span> <span class="c1"># kafka实例唯一id</span>
<span class="c1"># #############################</span>
<span class="c1"># 配置公网kafka实例，同时内网消费者使用内网IP访问</span>
<span class="nv">listeners</span><span class="o">=</span>PLAINTEXT://0.0.0.0:9092
advertised.listeners<span class="o">=</span>PLAINTEXT://221.112.112.111:9092
advertised.host.name<span class="o">=</span>bird-web-middleware.novalocal
<span class="c1"># ##############################</span>
num.network.threads<span class="o">=</span><span class="m">3</span>
num.io.threads<span class="o">=</span><span class="m">4</span>
socket.send.buffer.bytes<span class="o">=</span><span class="m">102400</span>
socket.receive.buffer.bytes<span class="o">=</span><span class="m">102400</span>
socket.request.max.bytes<span class="o">=</span><span class="m">104857600</span>
log.dirs<span class="o">=</span>/media/kafka_2.11-2.0.0/data <span class="c1"># 消息存储的路径</span>
num.partitions<span class="o">=</span><span class="m">3</span>
num.recovery.threads.per.data.dir<span class="o">=</span><span class="m">1</span>
log.retention.hours<span class="o">=</span><span class="m">72</span> <span class="c1"># 消息保存时间，默认168小时</span>
log.segment.bytes<span class="o">=</span><span class="m">1073741824</span>
log.retention.check.interval.ms<span class="o">=</span><span class="m">300000</span>
zookeeper.connect<span class="o">=</span><span class="m">192</span>.168.1.4:2181 <span class="c1"># zookeeper地址</span>
zookeeper.connection.timeout.ms<span class="o">=</span><span class="m">6000</span>
</pre></div>
</div>
<p>kafka后台启动</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./kafka-server-start.sh -daemon ../config/server.properties
</pre></div>
</div>
</div>
<div class="section" id="id5">
<h3>2.4 Kafka管理与监控<a class="headerlink" href="#id5" title="永久链接至标题">¶</a></h3>
<p>kafka二进制包bin目录下有很多命令行下管理工具，这里介绍的是非官方的三方可视化的管理工具。</p>
<div class="section" id="kafka-manager">
<h4>● Kafka Manager<a class="headerlink" href="#kafka-manager" title="永久链接至标题">¶</a></h4>
<p>常用的Kafka管理工具，包含Topic的创建、删除、重新分区等操作。在控制台上也可以看到相应topic的消费组及消费情况(offset值)。具体使用方法可以参考：https://github.com/yahoo/kafka-manager 。kafka-manager配置独立的zookeeper地址用于存储不同kafka实例的信息，从而管理不同的kafka集群。</p>
</div>
<div class="section" id="kafka-tool">
<h4>● Kafka Tool<a class="headerlink" href="#kafka-tool" title="永久链接至标题">¶</a></h4>
<p>一款C/S架构的Kafka UI Tool。具体使用方法可以参考：http://www.kafkatool.com/download.html 。使用Kafka Tool可以查看kafka实例的详细信息，并且可以可视化的看到kafka不同topic中的message信息。</p>
<p>Kafka Tool也可以查看消费者的offset和lag的消息数。但是当kafka集群中数据过多时，这个工具有明显的卡顿。</p>
</div>
</div>
</div>
<div class="section" id="id6">
<h2>三、配置高可用的Kafka集群<a class="headerlink" href="#id6" title="永久链接至标题">¶</a></h2>
<div class="section" id="kafka-cluster">
<h3>3.1 Kafka-Cluster说明<a class="headerlink" href="#kafka-cluster" title="永久链接至标题">¶</a></h3>
<p>日志在不同的网络环境下，有的需要走公网传输。搭建的kafka集群需要满足：支持内网和公网访问；Kafka集群作为日志搜集的中转，除了提供实时写入Elasticsearch，同时也可以使用Logstash将数据原样冷备到S3。</p>
</div>
<div class="section" id="id7">
<h3>3.2 下载包<a class="headerlink" href="#id7" title="永久链接至标题">¶</a></h3>
<p>Kafka版本：https://www.apache.org/dyn/closer.cgi?path=/kafka/2.2.0/kafka_2.11-2.2.0.tgz</p>
<p>Zookeeper版本：http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz</p>
</div>
<div class="section" id="id8">
<h3>3.3 配置与优化<a class="headerlink" href="#id8" title="永久链接至标题">¶</a></h3>
<div class="section" id="id9">
<h4>3.3.1 Zookeeper<a class="headerlink" href="#id9" title="永久链接至标题">¶</a></h4>
<blockquote>
<div><p>zookeeper-3.4.14/conf/zoo.cfg</p>
</div></blockquote>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># The number of milliseconds of each tick</span>
<span class="nv">tickTime</span><span class="o">=</span><span class="m">2000</span>
<span class="c1"># The number of ticks that the initial </span>
<span class="c1"># synchronization phase can take</span>
<span class="nv">initLimit</span><span class="o">=</span><span class="m">10</span>
<span class="c1"># The number of ticks that can pass between </span>
<span class="c1"># sending a request and getting an acknowledgement</span>
<span class="nv">syncLimit</span><span class="o">=</span><span class="m">5</span>
<span class="c1"># the directory where the snapshot is stored.</span>
<span class="c1"># do not use /tmp for storage, /tmp here is just </span>
<span class="c1"># example sakes.</span>
<span class="nv">dataDir</span><span class="o">=</span>/data/zookeeper
<span class="c1"># the port at which the clients will connect</span>
<span class="nv">clientPort</span><span class="o">=</span><span class="m">2181</span>
server.1<span class="o">=</span>kafka-az3-0001:2888:3888
server.2<span class="o">=</span>kafka-az3-0002:2888:3888
server.3<span class="o">=</span>kafka-az3-0003:2888:3888
</pre></div>
</div>
<p>dataDir目录新增myid文件，不同机器id不同用于区分（0-255）</p>
<blockquote>
<div><p>启动Zookeeper</p>
</div></blockquote>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># start/restart/stop/status</span>
/opt/zookeeper-3.4.14/bin/zkServer.sh start
</pre></div>
</div>
<blockquote>
<div><p>查看集群状态</p>
</div></blockquote>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Leader主节点</span>
/opt/zookeeper-3.4.14/bin/zkServer.sh status
</pre></div>
</div>
</div>
<div class="section" id="id10">
<h4>3.3.2 Kafka<a class="headerlink" href="#id10" title="永久链接至标题">¶</a></h4>
<blockquote>
<div><p>/opt/kafka_2.11-2.2.0/config/server.properties</p>
</div></blockquote>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>broker.id<span class="o">=</span><span class="m">1</span> <span class="c1"># 每个Node id唯一</span>
<span class="nv">listeners</span><span class="o">=</span>PLAINTEXT://0.0.0.0:9092
advertised.listeners<span class="o">=</span>PLAINTEXT://192.168.1.3:9092
advertised.host.name<span class="o">=</span>kafka-az3-0003 <span class="c1"># hostname;/etc/hosts需要配置</span>
num.network.threads<span class="o">=</span><span class="m">3</span>
num.io.threads<span class="o">=</span><span class="m">8</span>
socket.send.buffer.bytes<span class="o">=</span><span class="m">102400</span>
socket.receive.buffer.bytes<span class="o">=</span><span class="m">102400</span>
socket.request.max.bytes<span class="o">=</span><span class="m">104857600</span>
log.dirs<span class="o">=</span>/data/kafka-logs <span class="c1"># 消息存储路径</span>
num.partitions<span class="o">=</span><span class="m">3</span>
num.recovery.threads.per.data.dir<span class="o">=</span><span class="m">1</span>
log.retention.hours<span class="o">=</span><span class="m">72</span>
log.segment.bytes<span class="o">=</span><span class="m">1073741824</span>
log.retention.check.interval.ms<span class="o">=</span><span class="m">300000</span>
zookeeper.connect<span class="o">=</span><span class="m">192</span>.168.1.1:2181,192.168.1.2:2181,192.168.1.3:2181
zookeeper.connection.timeout.ms<span class="o">=</span><span class="m">6000</span>
</pre></div>
</div>
<blockquote>
<div><p>启动</p>
</div></blockquote>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./kafka-server-start.sh -daemon ../config/server.properties
</pre></div>
</div>
</div>
</div>
<div class="section" id="id11">
<h3>3.4 Kafka的内外网流量分离<a class="headerlink" href="#id11" title="永久链接至标题">¶</a></h3>
<p>在Kafka实际使用过程中，有时候需要走公网生产消息，但是消费者是在内网。这时候如果流量全部走公网，除了带宽限制也会增加一部分流量成本。这时候需要配置外网流量走外网地址，内网走内网地址。Kafka服务器需要2张网卡或者使用云服务的弹性IP。这里以云服务器的弹性IP为例，修改配置如下：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>listener.security.protocol.map<span class="o">=</span>CLIENT:PLAINTEXT,REPLICATION:PLAINTEXT
advertised.listeners<span class="o">=</span>CLIENT://192.33.10.241:9092,REPLICATION://120.13.81.201:19092
<span class="nv">listeners</span><span class="o">=</span>CLIENT://0.0.0.0:9092,REPLICATION://0.0.0.0:19092
inter.broker.listener.name<span class="o">=</span>REPLICATION
</pre></div>
</div>
</div>
</div>
<div class="section" id="id12">
<h2>四、 Kafka常见问答<a class="headerlink" href="#id12" title="永久链接至标题">¶</a></h2>
<blockquote>
<div><p>1.kafka节点之间如何复制备份的？</p>
</div></blockquote>
<p>一个备份数量为n的集群允许n-1个节点失败。在所有备份节点中，有一个节点作为lead节点，这个节点保存了其它备份节点列表，并维持各个备份间的状体同步。</p>
<p>Leader处理此分区的所有的读写请求，而follower被动的复制数据。（所有的写都发给leader, 然后leader将消息发给follower。）</p>
<blockquote>
<div><p>2.kafka消息是否会丢失？为什么？</p>
</div></blockquote>
<p>通过request.required.acks属性进行配置：</p>
<p>0代表：不进行消息接收是否成功的确认(默认值)；</p>
<p>1代表：当Leader副本接收成功后，返回接收成功确认信息；</p>
<p>-1代表：当Leader和Follower副本都接收成功后，返回接收成功确认信息。</p>
<p>想要更高的吞吐量就设置：异步、ack=0；想要不丢失消息数据就选：同步、ack=-1策略</p>
<blockquote>
<div><p>3.kafka的leader选举机制是什么？</p>
</div></blockquote>
<p>Kafka会在Zookeeper上针对每个Topic维护一个称为ISR。如果某个分区的Leader不可用，Kafka就会从ISR集合中选择一个副本作为新的Leader。</p>
<blockquote>
<div><p>4.如果所有的ISR副本都失败了怎么办？</p>
</div></blockquote>
<p>此时有两种方法可选，一种是等待ISR集合中的副本复活，一种是选择任何一个立即可用的副本，而这个副本不一定是在ISR集合中。这两种方法各有利弊，实际生产中按需选择。</p>
<p>如果要等待ISR副本复活，虽然可以保证一致性，但可能需要很长时间。而如果选择立即可用的副本，则很可能该副本并不一致。</p>
<blockquote>
<div><p>5.kafka对硬件的配置有什么要求？</p>
</div></blockquote>
<p>网络吞吐量决定了Kafka能够处理的最大数据流量。它和磁盘存储是制约Kafka扩展规模的主要因素。</p>
<blockquote>
<div><p>6.kafka的消息保证有几种方式？</p>
</div></blockquote>
<p>同步和异步。</p>
</div>
<div class="section" id="id13">
<h2>五、附录<a class="headerlink" href="#id13" title="永久链接至标题">¶</a></h2>
<blockquote>
<div><p>Kafka教程</p>
</div></blockquote>
<p>http://orchome.com/kafka/index</p>
<blockquote>
<div><p>Kafka Manager</p>
</div></blockquote>
<p>https://github.com/yahoo/kafka-manager</p>
<blockquote>
<div><p>Kafka技术分享目录索引</p>
</div></blockquote>
<p>https://blog.csdn.net/lizhitao/article/details/39499283</p>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; 版权所有 2019, Rayzh.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>
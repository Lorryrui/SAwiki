<!DOCTYPE HTML>
<html>
  <head>
    <link rel="Stylesheet" type="text/css" href="/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/static/css/tango.css">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="alternate" type="application/atom+xml" href="atom.xml" title="Atom feed">
    <title>Logstash Demo - SA Reference</title>
    <meta name="keywords" content="SA"/>
    <meta name="description" content="SAwiki is a simple static site for SA Engineer."/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  </head>

  <body>
    <div id="container">
      
<div id="header">
  <div class="post-nav"><a href="/">Home</a>&nbsp;&#187;&nbsp;<a href="/#LogCollection">LogCollection</a>&nbsp;&#187;&nbsp;Logstash Demo
    <span class="updated">Page Updated&nbsp;
      2019-03-01 10:00
    </span></div>
</div>
<div class="clearfix"></div>

<div class="page_title">Logstash Demo</div>

  <h1 id="_1">实际业务日志解析案例</h1>
<h2 id="demo-1nginx">Demo 1：Nginx日志解析</h2>
<p>1.1  解析流程</p>
<p>​    Filebeat --&gt; Kafka --&gt; Logstash --&gt; Elasticsearch</p>
<p>1.2  Nginx日志配置要求</p>
<p>​    1.2.1 统一Nginx日志格式</p>
<div class="hlcode"><pre><span class="n">log_format</span> <span class="n">main</span> <span class="err">&#39;$</span><span class="n">remote_addr</span> <span class="o">-</span> <span class="err">$</span><span class="n">remote_user</span> <span class="p">[</span><span class="err">$</span><span class="n">time_local</span><span class="p">]</span> <span class="s">&quot;$request&quot;</span> <span class="err">&#39;</span>
                <span class="err">&#39;$</span><span class="n">status</span> <span class="err">$</span><span class="n">body_bytes_sent</span> <span class="s">&quot;$http_referer&quot;</span> <span class="err">&#39;</span>
               <span class="err">&#39;</span><span class="s">&quot;$http_user_agent&quot;</span> <span class="s">&quot;$http_x_forwarded_for&quot;</span> <span class="s">&quot;$request_time&quot;</span> <span class="s">&quot;$http_host&quot;</span><span class="err">&#39;</span><span class="p">;</span>
</pre></div>


<p>​     1.2.2 字段说明     </p>
<table>
<thead>
<tr>
<th align="left">字段名</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">remote_addr</td>
<td>客户端请求IP地址</td>
</tr>
<tr>
<td align="left">remote_user</td>
<td>用户</td>
</tr>
<tr>
<td align="left">time_local</td>
<td>时间戳</td>
</tr>
<tr>
<td align="left">request</td>
<td>请求内容</td>
</tr>
<tr>
<td align="left">status</td>
<td>HTTP状态码</td>
</tr>
<tr>
<td align="left">body_bytes_sent</td>
<td>发送的数据包大小</td>
</tr>
<tr>
<td align="left">http_referer</td>
<td>来源页面链接</td>
</tr>
<tr>
<td align="left">http_user_agent</td>
<td>用户客户端信息</td>
</tr>
<tr>
<td align="left">http_x_forwarded_for</td>
<td>反向代理时用户实际IP地址</td>
</tr>
<tr>
<td align="left">request_time</td>
<td>请求响应时间</td>
</tr>
<tr>
<td align="left">http_host</td>
<td>请求域名或者IP</td>
</tr>
</tbody>
</table>
<p>​        1.2.3 Nginx日志配置规范</p>
<p>​            1.2.3.1 日志文件名以  ${program_name}_access.log 命名，存放路径 /opt/nginx/logs</p>
<p>​            1.2.3.2  凌晨日志切割，存放在/opt/nginx/logs/archive</p>
<p>​        1.2.4  Nginx日志解析规则</p>
<div class="hlcode"><pre><span class="c">%{COMBINEDAPACHELOG} \&quot;%{IP:x_forwarded_for}\&quot; %{QS:request_time} %{QS:http_host}</span>
</pre></div>


<p>1.3  Filebeat配置参考</p>
<p>输出到Kafka：<a href="https://www.elastic.co/guide/en/beats/filebeat/current/kafka-output.html">https://www.elastic.co/guide/en/beats/filebeat/current/kafka-output.html</a></p>
<div class="hlcode"><pre><span class="n">filebeat</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span>
<span class="o">-</span> <span class="nb">type</span><span class="p">:</span> <span class="n">log</span>
  <span class="c"># Change to true to enable this input configuration.</span>
  <span class="n">enabled</span><span class="p">:</span> <span class="n">true</span>
  <span class="c"># Paths that should be crawled and fetched. Glob based paths.</span>
  <span class="n">paths</span><span class="p">:</span>
    <span class="o">-</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">nginx</span><span class="o">/</span><span class="n">logs</span><span class="o">/</span><span class="n">dmblapp_access</span><span class="o">.</span><span class="n">log</span>
  <span class="n">tags</span><span class="p">:</span> <span class="p">[</span><span class="s">&quot;dmblapp&quot;</span><span class="p">]</span> 
  <span class="n">fields</span><span class="p">:</span>
    <span class="n">serverip</span><span class="p">:</span> <span class="mf">192.168</span><span class="o">.</span><span class="mf">2.5</span>  <span class="c"># 新增当前服务器IP字段</span>
<span class="o">-</span> <span class="nb">type</span><span class="p">:</span> <span class="n">log</span>
  <span class="c"># Change to true to enable this input configuration.</span>
  <span class="n">enabled</span><span class="p">:</span> <span class="n">true</span>
  <span class="c"># Paths that should be crawled and fetched. Glob based paths.</span>
  <span class="n">paths</span><span class="p">:</span>
    <span class="o">-</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">nginx</span><span class="o">/</span><span class="n">logs</span><span class="o">/</span><span class="n">lhb_access</span><span class="o">.</span><span class="n">log</span>
  <span class="n">tags</span><span class="p">:</span> <span class="p">[</span><span class="s">&quot;lhb&quot;</span><span class="p">]</span>
  <span class="n">fields</span><span class="p">:</span>
    <span class="n">serverip</span><span class="p">:</span> <span class="mf">192.168</span><span class="o">.</span><span class="mf">2.5</span>
<span class="n">output</span><span class="o">.</span><span class="n">kafka</span><span class="p">:</span>
  <span class="c"># initial brokers for reading cluster metadata</span>
  <span class="n">hosts</span><span class="p">:</span> <span class="p">[</span><span class="s">&quot;kafka1:9092&quot;</span><span class="p">,</span> <span class="s">&quot;kafka2:9092&quot;</span><span class="p">,</span> <span class="s">&quot;kafka3:9092&quot;</span><span class="p">]</span>
  <span class="c"># message topic selection + partitioning</span>
  <span class="n">topic</span><span class="p">:</span> <span class="n">nginx_access_log</span>
  <span class="n">required_acks</span><span class="p">:</span> <span class="mi">1</span>
  <span class="n">compression</span><span class="p">:</span> <span class="n">gzip</span>
  <span class="n">max_message_bytes</span><span class="p">:</span> <span class="mi">1000000</span>
  <span class="n">version</span><span class="p">:</span> <span class="mf">0.10</span><span class="o">.</span><span class="mf">0.0</span>
</pre></div>


<p>1.4  Kafka配置说明</p>
<p>​        Kafka版本建议选择0.11以上。使用KafkaManager管理Kafka集群，Topic创建规则不使用点，如nginx.access调整为nginx_access。副本数和Broker数相同，分区数是Broker整数倍。</p>
<p>1.5  Logstash配置参考  </p>
<div class="hlcode"><pre><span class="nb">input</span> <span class="p">{</span>
    <span class="n">kafka</span> <span class="p">{</span>
        <span class="n">bootstrap_servers</span> <span class="o">=&gt;</span> <span class="s">&quot;kafka1:9092 kafka2:9092 kafka3:9092&quot;</span>
        <span class="n">group_id</span> <span class="o">=&gt;</span> <span class="s">&quot;nginx_access_consumer&quot;</span>  <span class="c"># 多台消费必须统一group_id</span>
        <span class="n">topics</span> <span class="o">=&gt;</span> <span class="p">[</span><span class="s">&quot;nginx_access_log&quot;</span><span class="p">]</span>
        <span class="n">consumer_threads</span> <span class="o">=&gt;</span> <span class="mi">3</span>
        <span class="n">auto_offset_reset</span> <span class="o">=&gt;</span> <span class="s">&quot;earliest&quot;</span>
        <span class="n">enable_auto_commit</span> <span class="o">=&gt;</span> <span class="s">&quot;true&quot;</span>
        <span class="n">codec</span> <span class="o">=&gt;</span> <span class="s">&quot;json&quot;</span>  <span class="c"># json</span>
    <span class="p">}</span>
<span class="p">}</span>


<span class="nb">filter</span> <span class="p">{</span>
    <span class="n">grok</span> <span class="p">{</span>
        <span class="n">match</span> <span class="o">=&gt;</span> <span class="p">{</span> <span class="s">&quot;message&quot;</span> <span class="o">=&gt;</span> <span class="s">&quot;%{COMBINEDAPACHELOG} </span><span class="se">\&quot;</span><span class="s">%{IP:x_forwarded_for}</span><span class="se">\&quot;</span><span class="s"> %{QS:request_time} %{QS:http_host}&quot;</span><span class="p">}</span>
    <span class="p">}</span>
    <span class="n">date</span> <span class="p">{</span>
        <span class="n">match</span> <span class="o">=&gt;</span> <span class="p">[</span><span class="s">&quot;timestamp&quot;</span><span class="p">,</span><span class="s">&quot;dd/MMM/YYYY:HH:mm:ss +0800&quot;</span><span class="p">]</span>
    <span class="p">}</span>
    <span class="n">geoip</span> <span class="p">{</span> <span class="c"># IP地址解析</span>
        <span class="n">source</span> <span class="o">=&gt;</span> <span class="s">&quot;x_forwarded_for&quot;</span>
        <span class="n">target</span> <span class="o">=&gt;</span> <span class="s">&quot;geoip&quot;</span>
        <span class="n">database</span> <span class="o">=&gt;</span> <span class="s">&quot;/etc/logstash/GeoLite2-City.mmdb&quot;</span>
        <span class="n">add_field</span> <span class="o">=&gt;</span> <span class="p">[</span> <span class="s">&quot;[geoip][coordinates]&quot;</span><span class="p">,</span> <span class="s">&quot;%{[geoip][longitude]}&quot;</span> <span class="p">]</span>
        <span class="n">add_field</span> <span class="o">=&gt;</span> <span class="p">[</span> <span class="s">&quot;[geoip][coordinates]&quot;</span><span class="p">,</span> <span class="s">&quot;%{[geoip][latitude]}&quot;</span>  <span class="p">]</span>
    <span class="p">}</span>
    <span class="n">mutate</span> <span class="p">{</span>
        <span class="n">convert</span> <span class="o">=&gt;</span> <span class="p">[</span> <span class="s">&quot;[geoip][coordinates]&quot;</span><span class="p">,</span> <span class="s">&quot;float&quot;</span><span class="p">]</span>
           <span class="p">}</span>
    <span class="n">useragent</span> <span class="p">{</span> <span class="c"># 客户端信息解析</span>
        <span class="n">target</span> <span class="o">=&gt;</span> <span class="s">&quot;useragent&quot;</span>
        <span class="n">source</span> <span class="o">=&gt;</span> <span class="s">&quot;agent&quot;</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="n">output</span> <span class="p">{</span>
    <span class="n">elasticsearch</span> <span class="p">{</span>
    <span class="n">hosts</span> <span class="o">=&gt;</span> <span class="p">[</span><span class="s">&quot;es1:9200&quot;</span><span class="p">,</span><span class="s">&quot;es2:9200&quot;</span><span class="p">,</span><span class="s">&quot;es3:9200&quot;</span><span class="p">]</span>
    <span class="n">index</span> <span class="o">=&gt;</span> <span class="s">&quot;nginx_access-%{+yyyy.MM.dd}&quot;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>


<p>1.6  Kibana搜索与展示</p>
<p>​        根据index在Kibana上建立nginx_access-*，然后在Discover中可以查看具体字段解析以及搜索内容。</p>
<p><img alt="" src="..\attach\kibana.jpg" /></p>
  <div class="relation">
    <h2>Related</h2>
    <ul>
    
    <li><a href="/LogCollection/基于ELK的日志平台规划与落地.html">ELK Stack</a></li>
    
    </ul>
  </div>
    </div>
    <div id="footer">
      <span>
        <p>Copyright © 2019 Lorryrui.
        Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.</p>
        <p>Site Generated 2019-04-16 08:51:00</p>
      </span>
    </div>

    
    
  </body>
</html>